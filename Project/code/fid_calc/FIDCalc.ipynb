{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculating the frechet inception distance in Keras\n",
    "import os\n",
    "import numpy\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy import asarray\n",
    "from numpy.random import randint\n",
    "from scipy.linalg import sqrtm\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(imageroot):\n",
    "    images = []\n",
    "    for filename in os.listdir(imageroot):\n",
    "        img = cv2.imread(os.path.join(imageroot, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    ret = np.asarray(images)\n",
    "    print('Data loaded, shape:', ret.shape)\n",
    "    return ret\n",
    "\n",
    "def get_images_gan(imageroot):\n",
    "    images = []\n",
    "    for filename in os.listdir(imageroot):\n",
    "        if filename.endswith('fake_B.png'):\n",
    "            img = cv2.imread(os.path.join(imageroot, filename))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "    ret = np.asarray(images)\n",
    "    print('Data loaded, shape:', ret.shape)\n",
    "    return ret\n",
    "\n",
    "# scale an array of images to a new size\n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return asarray(images_list)\n",
    "\n",
    "# calculate frechet inception distance\n",
    "def calculate_fid(model, images1, images2):\n",
    "    # calculate activations\n",
    "    act1 = model.predict(images1)\n",
    "    act2 = model.predict(images2)\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARTOON_DIR = 'face_cartoon'\n",
    "LS_DIR = 'cart_cyclegan_ls/test_latest/images'\n",
    "VAN_DIR = 'cart_cyclegan_vanilla/test_latest/images'\n",
    "W_DIR = 'cart_cyclegan_wgan/test_latest/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, shape: (5000, 256, 256, 3)\n",
      "Data loaded, shape: (1894, 256, 256, 3)\n",
      "Prepared (1000, 256, 256, 3) (1894, 256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled (1000, 299, 299, 3) (1894, 299, 299, 3)\n",
      "FID (same): -0.000\n",
      "FID (different): 58.113\n"
     ]
    }
   ],
   "source": [
    "# prepare the inception v3 model\n",
    "model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
    "# define two fake collections of images\n",
    "images1 = (get_images(CARTOON_DIR))[:1000]\n",
    "images2 = get_images_gan(LS_DIR)\n",
    "print('Prepared', images1.shape, images2.shape)\n",
    "# convert integer to floating point values\n",
    "images1 = images1.astype('float32')\n",
    "images2 = images2.astype('float32')\n",
    "# resize images\n",
    "images1 = scale_images(images1, (299,299,3))\n",
    "images2 = scale_images(images2, (299,299,3))\n",
    "print('Scaled', images1.shape, images2.shape)\n",
    "# pre-process images\n",
    "images1 = preprocess_input(images1)\n",
    "images2 = preprocess_input(images2)\n",
    "# fid between images1 and images2\n",
    "fid = calculate_fid(model, images1, images2)\n",
    "print('FID (different): %.3f' % fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, shape: (1894, 256, 256, 3)\n",
      "Prepared (1000, 299, 299, 3) (1894, 256, 256, 3)\n",
      "Scaled (1000, 299, 299, 3) (1894, 299, 299, 3)\n",
      "FID (different): 58.803\n"
     ]
    }
   ],
   "source": [
    "# define two fake collections of images\n",
    "images2 = get_images_gan(VAN_DIR)\n",
    "print('Prepared', images1.shape, images2.shape)\n",
    "# convert integer to floating point values\n",
    "images2 = images2.astype('float32')\n",
    "# resize images\n",
    "images2 = scale_images(images2, (299,299,3))\n",
    "print('Scaled', images1.shape, images2.shape)\n",
    "# pre-process images\n",
    "images2 = preprocess_input(images2)\n",
    "# fid between images1 and images2\n",
    "fid = calculate_fid(model, images1, images2)\n",
    "print('FID (different): %.3f' % fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, shape: (1894, 256, 256, 3)\n",
      "Prepared (1000, 299, 299, 3) (1894, 256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled (1000, 299, 299, 3) (1894, 299, 299, 3)\n",
      "FID (different): 138.299\n"
     ]
    }
   ],
   "source": [
    "# define two fake collections of images\n",
    "images2 = get_images_gan(W_DIR)\n",
    "print('Prepared', images1.shape, images2.shape)\n",
    "# convert integer to floating point values\n",
    "images2 = images2.astype('float32')\n",
    "# resize images\n",
    "images2 = scale_images(images2, (299,299,3))\n",
    "print('Scaled', images1.shape, images2.shape)\n",
    "# pre-process images\n",
    "images2 = preprocess_input(images2)\n",
    "# fid between images1 and images2\n",
    "fid = calculate_fid(model, images1, images2)\n",
    "print('FID (different): %.3f' % fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bitd3d6c13e347747d4b75cdea4c808ae91"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
